{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to create a good title for video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "british_youtube = pd.read_csv(\"GBvideos.csv\")\n",
    "canadian_youtube = pd.read_csv(\"CAvideos.csv\")\n",
    "us_youtube = pd.read_csv(\"USvideos.csv\")\n",
    "\n",
    "videos = pd.concat([canadian_youtube, british_youtube,us_youtube])\n",
    "videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What makes videos popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CorrelationMatrix:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def draw(self):\n",
    "        corr_matrix = self.df[['views', 'likes', 'dislikes', 'comment_count']].corr()\n",
    "        sn.heatmap(corr_matrix, annot=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "CorrelationMatrix(videos).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class YoutubeNormalizer:\n",
    "\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv\n",
    "\n",
    "    def decide_about_popular(self):\n",
    "        lots_views = self.csv.views.quantile(0.8)\n",
    "        comments_median = self.csv.comment_count.quantile(0.6)\n",
    "        lots_of_dislike = self.csv.dislikes.quantile(0.8)\n",
    "        self.csv['popular'] = 0\n",
    "        self.csv.loc[(comments_median < self.csv.comment_count) & (self.csv.views > lots_views), 'popular'] = 1\n",
    "        self.csv.loc[(self.csv.dislikes > lots_of_dislike) & (self.csv.likes > self.csv.dislikes), 'popular'] = 1\n",
    "\n",
    "    def get_normalized_data(self):\n",
    "        self.csv.drop_duplicates(subset=\"title\", keep='first', inplace=True)\n",
    "        self.decide_about_popular()\n",
    "        title_with_popular = self.csv[['title', 'popular']]\n",
    "        return title_with_popular\n",
    "\n",
    "\n",
    "normalized_data = YoutubeNormalizer(videos).get_normalized_data()\n",
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "st = PorterStemmer()\n",
    "\n",
    "\n",
    "class NormalizedTitle:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    @staticmethod\n",
    "    def avg_word(sentence):\n",
    "        words = sentence.split()\n",
    "        return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "    def parameters_extraction(self):\n",
    "        self.df['word_count'] = self.df['title'].apply(lambda x: len(str(x).split(\" \")))\n",
    "        self.df['char_count'] = self.df['title'].str.len()\n",
    "        self.df['avg_word'] = self.df['title'].apply(lambda x: self.avg_word(x))\n",
    "        self.df['stopwords'] = self.df['title'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "        self.df['hastags'] = self.df['title'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "        self.df['numerics'] = self.df['title'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "    def text_preparation(self):\n",
    "        self.df['title'] = self.df['title'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "        self.df['title'] = self.df['title'].str.replace('[^\\w\\s]', '')\n",
    "        self.df['title'] = self.df['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "        freq = pd.Series(' '.join(self.df['title']).split()).value_counts()\n",
    "        common_words = freq[freq > 250]\n",
    "        common_words = list(common_words.index)\n",
    "        self.df['title'] = self.df['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in common_words))\n",
    "        rare_words = common_words = freq[freq < 5]\n",
    "        rare_words = list(common_words.index)\n",
    "        self.df['title'] = self.df['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare_words))\n",
    "        self.df['title'] = self.df['title'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "        self.df['title'] = self.df['title'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "    def process(self):\n",
    "        self.parameters_extraction()\n",
    "        self.text_preparation()\n",
    "        return self.df\n",
    "\n",
    "\n",
    "normalized_title = NormalizedTitle(normalized_data).process()\n",
    "normalized_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, naive_bayes, svm, ensemble\n",
    "\n",
    "\n",
    "class TitleVectorization:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def process(self):\n",
    "        train_df, test_df = train_test_split(\n",
    "            self.df,\n",
    "            test_size=0.1,\n",
    "            stratify=self.df['popular'],\n",
    "        )\n",
    "        vectorizer = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1, 2), analyzer=\"word\")\n",
    "        vectorizer.fit(train_df)\n",
    "        return train_df, test_df, vectorizer\n",
    "\n",
    "\n",
    "(train_title_popularity, test_title_popularity, vectorizer) = TitleVectorization(normalized_title).process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self, train_df, test_df, vectorizer, strategy):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.vectorizer = vectorizer\n",
    "        if strategy == 'LogisticRegression':\n",
    "            self.model = LogisticRegression(class_weight='balanced', dual=False)\n",
    "        elif strategy == 'NAIVE BAYES':\n",
    "            self.model = naive_bayes.MultinomialNB()\n",
    "        elif strategy == 'SVM':\n",
    "            self.model = svm.SVC()\n",
    "        elif strategy == 'RANDOM FORREST':\n",
    "            self.model = ensemble.RandomForestClassifier()\n",
    "\n",
    "    def train(self):\n",
    "        transformed = vectorizer.transform(self.train_df['title'])\n",
    "        self.model.fit(transformed, self.train_df['popular'])\n",
    "\n",
    "    def show_model_statistic(self):\n",
    "        vectorized = vectorizer.transform(self.test_df['title'])\n",
    "        predicted = self.model.predict(vectorized)\n",
    "        target = self.test_df['popular']\n",
    "        print(metrics.classification_report(target, predicted, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression_classification = Classification(train_df=train_title_popularity, test_df=test_title_popularity, vectorizer=vectorizer,\n",
    "                                                    strategy='LogisticRegression')\n",
    "logistic_regression_classification.train()\n",
    "logistic_regression_classification.show_model_statistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "naive_bayes_classification = Classification(train_df=train_title_popularity, test_df=test_title_popularity, vectorizer=vectorizer,\n",
    "               strategy='NAIVE BAYES')\n",
    "naive_bayes_classification.train()\n",
    "naive_bayes_classification.show_model_statistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svm_classification = Classification(train_df=train_title_popularity, test_df=test_title_popularity, vectorizer=vectorizer,\n",
    "               strategy='SVM')\n",
    "svm_classification.train()\n",
    "svm_classification.show_model_statistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FORREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_forest_tree = Classification(train_df=train_title_popularity, test_df=test_title_popularity, vectorizer=vectorizer,\n",
    "               strategy='RANDOM FORREST')\n",
    "random_forest_tree.train()\n",
    "random_forest_tree.show_model_statistic()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
